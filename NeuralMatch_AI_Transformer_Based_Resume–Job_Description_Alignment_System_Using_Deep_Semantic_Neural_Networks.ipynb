{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸŽ¯ Project Objective**\n",
        "\n",
        "The objective of NeuralMatch AI is to design and implement a deep learningâ€“powered Resume Screening and ATS Scoring System that leverages advanced neural network architectures, specifically Transformer-based sentence embeddings, to evaluate semantic alignment between a candidateâ€™s resume and a job description.\n",
        "\n",
        "This project emphasizes the application of modern deep neural networks in Natural Language Processing (NLP) to move beyond traditional keyword matching and enable contextual understanding of text.\n",
        "\n",
        "The system aims to:\n",
        "\n",
        "Utilize Transformer-based neural networks (Sentence-BERT) to generate high-dimensional semantic embeddings of resume and job description content.\n",
        "\n",
        "Compute contextual similarity using cosine similarity in embedding space.\n",
        "\n",
        "Integrate traditional NLP techniques (TF-IDF) with deep semantic representations for hybrid scoring.\n",
        "\n",
        "Quantify recruiter-relevant signals such as action verbs, measurable impact, and keyword alignment.\n",
        "\n",
        "Produce a weighted, recruiter-grade ATS score reflecting real-world hiring evaluation logic.\n",
        "\n",
        "By combining deep representation learning with statistical text analysis, this project demonstrates how neural networks can model human-like understanding in recruitment automation systems."
      ],
      "metadata": {
        "id": "rjrLXG7ANKeV"
      },
      "id": "rjrLXG7ANKeV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ§  Neural Network Emphasis (Core Intelligence of the System)**\n",
        "\n",
        "At the heart of this system lies:\n",
        "\n",
        "A Transformer-based Neural Network (all-MiniLM-L6-v2)\n",
        "\n",
        "Built on the BERT architecture\n",
        "\n",
        "Trained using contrastive learning for semantic similarity tasks\n",
        "\n",
        "The neural network:\n",
        "\n",
        "Converts sentences into dense vector embeddings\n",
        "\n",
        "Captures contextual meaning rather than just word overlap\n",
        "\n",
        "Understands relationships between concepts (e.g., â€œbuilt ML modelâ€ â‰ˆ â€œdeveloped predictive systemâ€)\n",
        "\n",
        "Unlike rule-based ATS systems, this architecture models semantic intelligence using deep learning representations."
      ],
      "metadata": {
        "id": "H72iJtExNOxy"
      },
      "id": "H72iJtExNOxy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621f4613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621f4613",
        "outputId": "c4583318-0c93-4e11-b9be-c02640b383a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.9)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pdfminer.six==20251230 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20251230)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.5.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.10.0+cu128)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers) (1.3.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (0.24.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (3.0)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber sentence-transformers scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import files\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 1ï¸âƒ£ Upload Resume\n",
        "# ---------------------------------------------\n",
        "print(\"Upload Resume (PDF)\")\n",
        "uploaded = files.upload()\n",
        "resume_file = list(uploaded.keys())[0]\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 2ï¸âƒ£ Extract Resume Text\n",
        "# ---------------------------------------------\n",
        "def extract_text(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            content = page.extract_text()\n",
        "            if content:\n",
        "                text += content + \" \"\n",
        "    return text\n",
        "\n",
        "resume_raw = extract_text(resume_file)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 3ï¸âƒ£ Clean Text\n",
        "# ---------------------------------------------\n",
        "def clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9% ]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "resume_text = clean(resume_raw)\n",
        "\n",
        "jd_raw = input(\"\\nPaste Job Description:\\n\")\n",
        "jd_text = clean(jd_raw)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 4ï¸âƒ£ Load Semantic Model\n",
        "# ---------------------------------------------\n",
        "print(\"\\nLoading Model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Model Loaded âœ…\")\n",
        "\n",
        "# Sentence-Level Semantic Matching\n",
        "resume_sentences = resume_raw.split(\".\")\n",
        "jd_sentences = jd_raw.split(\".\")\n",
        "\n",
        "resume_emb = model.encode(resume_sentences)\n",
        "\n",
        "semantic_scores = []\n",
        "for sentence in jd_sentences:\n",
        "    jd_emb = model.encode([sentence])[0]\n",
        "    sims = cosine_similarity([jd_emb], resume_emb)[0]\n",
        "    semantic_scores.append(np.max(sims))\n",
        "\n",
        "semantic_score = np.mean(semantic_scores)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 5ï¸âƒ£ Dynamic Keyword Extraction (TF-IDF)\n",
        "# ---------------------------------------------\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=100)\n",
        "tfidf = vectorizer.fit_transform([resume_text, jd_text])\n",
        "\n",
        "features = vectorizer.get_feature_names_out()\n",
        "\n",
        "resume_vec = tfidf[0].toarray()[0]\n",
        "jd_vec = tfidf[1].toarray()[0]\n",
        "\n",
        "resume_keywords = set([features[i] for i in range(len(features)) if resume_vec[i] > 0])\n",
        "jd_keywords = set([features[i] for i in range(len(features)) if jd_vec[i] > 0])\n",
        "\n",
        "keyword_overlap = resume_keywords.intersection(jd_keywords)\n",
        "\n",
        "keyword_score = len(keyword_overlap) / len(jd_keywords) if len(jd_keywords) > 0 else 0\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 6ï¸âƒ£ Business Verb Weighting\n",
        "# ---------------------------------------------\n",
        "business_verbs = [\n",
        "    \"led\",\"delivered\",\"optimized\",\"improved\",\"increased\",\n",
        "    \"reduced\",\"implemented\",\"developed\",\"built\",\n",
        "    \"supported\",\"drove\",\"analyzed\",\"designed\",\"managed\"\n",
        "]\n",
        "\n",
        "verb_hits = sum([1 for verb in business_verbs if verb in resume_text])\n",
        "verb_score = min(verb_hits / len(business_verbs), 1)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 7ï¸âƒ£ Impact Score (Numbers & % Detection)\n",
        "# ---------------------------------------------\n",
        "impact_patterns = re.findall(r'\\d+%|\\d+\\s?percent|\\d+\\s?x', resume_text)\n",
        "impact_score = min(len(impact_patterns) / 5, 1)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 8ï¸âƒ£ JD Responsibility Boost\n",
        "# ---------------------------------------------\n",
        "important_jd_terms = [\n",
        "    \"responsibilities\",\n",
        "    \"requirements\",\n",
        "    \"role\",\n",
        "    \"skills\",\n",
        "    \"experience\"\n",
        "]\n",
        "\n",
        "jd_weight = 1.2 if any(term in jd_text for term in important_jd_terms) else 1.0\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 9ï¸âƒ£ Final Recruiter-Grade Score\n",
        "# ---------------------------------------------\n",
        "final_score = (\n",
        "    0.45 * semantic_score +\n",
        "    0.30 * keyword_score +\n",
        "    0.15 * verb_score +\n",
        "    0.10 * impact_score\n",
        ") * jd_weight\n",
        "\n",
        "final_score = min(final_score, 1)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# ðŸ”Ÿ Results\n",
        "# ---------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(f\"Semantic Score: {semantic_score*100:.2f}%\")\n",
        "print(f\"Keyword Match: {keyword_score*100:.2f}%\")\n",
        "print(f\"Business Verb Score: {verb_score*100:.2f}%\")\n",
        "print(f\"Impact Score: {impact_score*100:.2f}%\")\n",
        "print(f\"\\nðŸ”¥ FINAL ATS SCORE: {final_score*100:.2f}%\")\n",
        "print(\"==============================\")\n",
        "\n",
        "print(\"\\nâœ… Matched Keywords:\", list(keyword_overlap))\n",
        "print(\"\\nâŒ Missing Keywords:\", list(jd_keywords - resume_keywords))\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Interpretation\n",
        "# ---------------------------------------------\n",
        "if final_score > 0.75:\n",
        "    print(\"\\nðŸŸ¢ Recruiter-Level Strong Match\")\n",
        "elif final_score > 0.55:\n",
        "    print(\"\\nðŸŸ¡ Moderate Match â€“ Improve Alignment\")\n",
        "else:\n",
        "    print(\"\\nðŸ”´ Needs Optimization\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663,
          "referenced_widgets": [
            "9f7d94ad74f541538fcc32654664ab56",
            "7491ea85eba042c9bb07b057ae0d52d7",
            "6e9d46c00fdb42e582af25d347e71843",
            "b8413c8433ae438ca38e59eac2b575b0",
            "f06fcef9e2f64be9a9aad655ee3223eb",
            "81cf53dc7ae04f2cbbda391f73e56818",
            "59aeb4f4a25e46b9b84ba113d85f7768",
            "8c27ca7e9d2c4a11afecdef084be60d9",
            "b577ef9e5e8a46a7b07f6d77c7ccbbe1",
            "eed83aa1963c4f76856cc738b92dc7c7",
            "bf71c5236c324e618f9fa1c4d5379dd0"
          ]
        },
        "id": "oNDLwHx8ORVj",
        "outputId": "8e700b74-4088-4aa7-a309-d6f6819cdb56"
      },
      "id": "oNDLwHx8ORVj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Resume (PDF)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c0aa603-da8e-4214-b97e-1daaaa818e85\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9c0aa603-da8e-4214-b97e-1daaaa818e85\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CV-Ramayan.pdf to CV-Ramayan.pdf\n",
            "\n",
            "Paste Job Description:\n",
            "We are seeking a detail-oriented and enthusiastic Fresher Data Analyst to join our dynamic team.  The ideal candidate will have a strong foundation in data analysis principles and a passion for transforming raw data into meaningful insights that drive business decisions.   Key Responsibilities:  Data Collection & Processing: Extract, clean, and organize data from various sources using tools like SQL and Excel.  Data Analysis: Perform exploratory data analysis to identify trends, patterns, and anomalies in datasets.  Data Visualization: Create clear and compelling visualizations using Tableau, Power BI, or Google Looker Studio to communicate findings.  Reporting: Develop and maintain reports and dashboards that support business operations and strategic planning.  Collaboration: Work closely with cross-functional teams to understand data needs and deliver actionable insights.  Continuous Learning: Stay updated on industry trends, best practices, and emerging tools in data analytics.\n",
            "\n",
            "Loading Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f7d94ad74f541538fcc32654664ab56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded âœ…\n",
            "\n",
            "==============================\n",
            "Semantic Score: 62.64%\n",
            "Keyword Match: 86.84%\n",
            "Business Verb Score: 50.00%\n",
            "Impact Score: 40.00%\n",
            "\n",
            "ðŸ”¥ FINAL ATS SCORE: 78.89%\n",
            "==============================\n",
            "\n",
            "âœ… Matched Keywords: ['data', 'visualization', 'decisions', 'datasets', 'actionable', 'google', 'analyst', 'exploratory', 'excel', 'tools', 'team', 'collaboration', 'support', 'raw', 'detail', 'analysis', 'insights', 'business', 'bi', 'analytics', 'using', 'strong', 'dynamic', 'visualizations', 'trends', 'patterns', 'power', 'sql', 'clear', 'identify', 'reporting', 'tableau', 'transforming']\n",
            "\n",
            "âŒ Missing Keywords: ['candidate', 'closely', 'clean', 'communicate', 'compelling']\n",
            "\n",
            "ðŸŸ¢ Recruiter-Level Strong Match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ Conclusion**\n",
        "\n",
        "The NeuralMatch AI project successfully demonstrates the practical application of deep neural networks and transformer-based language models in solving a real-world recruitment automation problem.\n",
        "\n",
        "By leveraging Sentence Transformers built on advanced neural architectures, the system:\n",
        "\n",
        "Achieves contextual understanding of resume and job descriptions\n",
        "\n",
        "Moves beyond surface-level keyword matching\n",
        "\n",
        "Quantifies candidateâ€“role alignment using embedding similarity\n",
        "\n",
        "Integrates deep learning with interpretable scoring mechanisms\n",
        "\n",
        "This project highlights strong competency in:\n",
        "\n",
        "Deep Learning\n",
        "\n",
        "Transformer Architectures\n",
        "\n",
        "NLP with Neural Networks\n",
        "\n",
        "Semantic Embeddings\n",
        "\n",
        "Hybrid AI Systems (Neural + Statistical Methods)\n",
        "\n",
        "Ultimately, NeuralMatch AI showcases how modern neural networks can replicate aspects of human semantic reasoning, making recruitment evaluation more intelligent, scalable, and data-driven."
      ],
      "metadata": {
        "id": "KlNpL7PINUjR"
      },
      "id": "KlNpL7PINUjR"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f7d94ad74f541538fcc32654664ab56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7491ea85eba042c9bb07b057ae0d52d7",
              "IPY_MODEL_6e9d46c00fdb42e582af25d347e71843",
              "IPY_MODEL_b8413c8433ae438ca38e59eac2b575b0"
            ],
            "layout": "IPY_MODEL_f06fcef9e2f64be9a9aad655ee3223eb"
          }
        },
        "7491ea85eba042c9bb07b057ae0d52d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81cf53dc7ae04f2cbbda391f73e56818",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_59aeb4f4a25e46b9b84ba113d85f7768",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "6e9d46c00fdb42e582af25d347e71843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c27ca7e9d2c4a11afecdef084be60d9",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b577ef9e5e8a46a7b07f6d77c7ccbbe1",
            "value": 103
          }
        },
        "b8413c8433ae438ca38e59eac2b575b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eed83aa1963c4f76856cc738b92dc7c7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bf71c5236c324e618f9fa1c4d5379dd0",
            "value": "â€‡103/103â€‡[00:00&lt;00:00,â€‡504.10it/s,â€‡Materializingâ€‡param=pooler.dense.weight]"
          }
        },
        "f06fcef9e2f64be9a9aad655ee3223eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81cf53dc7ae04f2cbbda391f73e56818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59aeb4f4a25e46b9b84ba113d85f7768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c27ca7e9d2c4a11afecdef084be60d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b577ef9e5e8a46a7b07f6d77c7ccbbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eed83aa1963c4f76856cc738b92dc7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf71c5236c324e618f9fa1c4d5379dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}